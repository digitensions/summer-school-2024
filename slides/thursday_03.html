
<!DOCTYPE html>
<html>
  <head>
    <title>Digital Summer School 2024: THU03</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <link rel="stylesheet" href="../style.css">  </head>
  <body>
    <textarea id="source">


class: center, middle, titlepage
### THU03: *Scaling Digital Preservation Workflows*

---
class: contentpage
### **Agenda**
      
1. Scheduling Tools  
 1.1 Unix Cron   
 1.2 Windows Task Scheduler   

2. Environmental variables   
 2.1 Setting them in Unix/Windows  
 2.2 Accessing them in code  

3. Expanding workflows with APIs   
 3.1 RESTful API basics  
 3.2 Requests library  
 3.3 Rate limiting  
 3.4 AWS S3 cloud storage

4. Elasticsearch and MySQL connections  
 4.1 Elasticsearch Indexing, searching documents     
 4.2 Connecting to MySQL databases  
 4.3 Search and retrieval with sqlite3 

---
class: contentpage
### **1. Scheduling Tools**

Script scheduling involves automating the execution of scripts or programs at predetermined times or intervals. This is crucial for:  
- Routine maintenance tasks
- Automated backups
- Periodic data processing
- Recurring reports generation

Key components of script scheduling include the scheduling mechanism, exectution parameters and the script, programme or command.

```sh
# Example of job definition:
# .---------------- minute (0 - 59)
# |  .------------- hour (0 - 23)
# |  |  .---------- day of month (1 - 31)
# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
# |  |  |  |  |
# *  *  *  *  * user-name command to be executed
47 6    * * 7   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )
#
```
---
class: contentpage
### **1.1 Unix Cron**

Cron is the standard Unix scheduler for Mac and Linux. It uses crontab files to manage schedules, structing the timing parameters: `Minute Hour Day Month DayOfWeek Command`  

```sh
# MIN    HR    DAY  MTH  DAY/WK  USR   FLOCK LOCK DETAILS                                         COMMAND
 */15    *     *    *    *       root  /usr/bin/flock -w 0 --verbose /var/run/dpx_rawcook.lock    ${DPX_SCRIPTS}qnap/dpx_rawcook.sh
```
This example runs a shell script for automated DPX encoding every 15 minutes. The Linux Flock lock flock can help prevent multiple instances of a script from running concurrently, essential for maintaining system stability and data integrity.

Advanced cron features include:     
- Reboot tasks at system startup using `@reboot` prefix
- Environment variable setting by adding $PATH information into cron
- Log redirection to capture stdout/stderr `>> /path/to/logfile 2>&1`

To launch a cron editing session you can call one of the following:
- `crontab -e` opens a user's crontab editing. All users including root user can schedule scripts here
- `/etc/crontab/` is a system wide crontab intended for system scheduling purposes

---
class: contentpage
### **1.1 Unix Cron**

```sh
# /etc/crontab: system-wide crontab
# Unlike any other crontab you don't have to run the `crontab'
# command to install the new version when you edit this file
# and files in /etc/cron.d. These files also have username fields.

# MIN    HR    DAY  MTH  DAY/WK  USR   FLOCK LOCK DETAILS                                             COMMAND
 */15    *     *    *    *       root  /usr/bin/flock -w 0 --verbose /var/run/dpx_rawcook.lock       ${DPX_SCRIPTS}qnap/dpx_rawcook.sh
 0       */4   *    *    *       root  /usr/bin/flock -w 0 --verbose /var/run/dpx_post_rawcook.lock  ${DPX_SCRIPTS}qnap/dpx_post_rawcook.sh
 30      */4   *    *    *       root  /usr/bin/flock -w 0 --verbose /var/run/dpx_check_script.lock  ${DPX_SCRIPTS}qnap/dpx_check_script.sh
 0       20    *    *    5       root  ${PY3_ENV}  ${DPX_SCRIPTS}qnap/dpx_part_whole_move.py > /tmp/python_cron.log 2>&1
 */5     *     *    *    *       root  ${CODE}flock_rebuild.sh

# Example of job definition:
# .---------------- minute (0 - 59)
# |  .------------- hour (0 - 23)
# |  |  .---------- day of month (1 - 31)
# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
# |  |  |  |  |
# *  *  *  *  * user-name command to be executed
17 *    * * *   root    cd / && run-parts --report /etc/cron.hourly
25 6    * * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.daily )
47 6    * * 7   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.weekly )
52 6    1 * *   root    test -x /usr/sbin/anacron || ( cd / && run-parts --report /etc/cron.monthly )
#
```
---
class: contentpage
### **1.1 Unix Cron**

When cron jobs fail it can be hard to identify the cause of the problem.
- Syntax error somewhere in a schedule line
- Incorrect numbers in designated column (ie, 8, or 9 in a day of the week)
- Unknown user or mistyped user name
- Insufficient user permissions for the command

When the crontab fails to run it can take some time to understand what the problems is:
- Restart crontab after making challenges
  ```sh
  sudo systemctl restart cron
  ```
- Check the logs
  ```sh
  /var/log/cron (CentOS)  /var/log/syslog (Ubuntu or Debian)
  ```
- Run CronitorCLI software which includes shell command to test run any job emulating cron, with debugging
  ```sh
  cronitor select
  ```
---
class: contentpage
### **1.2 Windows Task Scheduler**

The Windows Task Scheduler is the equivalent to cron.  

Graphical interface for creating and managing scheduled tasks, which can also be managed via the command line (schtasks)

You can launch the Task Scheduler GUI from `CMD.exe` or `Powershell` by typing:
```sh
taskschd.msc
```

The Task scheduler offers hey features:
- Flexible scheduling options (daily, weekly, monthly, etc.)
- Ability to set conditions (e.g., run only when idle)
- Can run scripts, programs, or send emails

Example schtasks command:
```sh
schtasks /create /tn "Backup daily" /tr C:\scripts\backup.bat /sc daily /st 12:00
```
This command creates a task named "Daily Backup" that runs backup.bat daily at 12:00 Noon  

---
class: contentpage
### **2. Environmental variables**

Environment variables are dynamic values that can affect the behavior of running processes on a computer. They are part of the environment in which a process runs and are typically used for:  
- Store configuration settings 
- Manage system-wide settings
- Pass information between processes
- Enhancing security by keeping sensitive data out of code
- Facilitate cross-environment development

Advantages when using them in your code:  

- If dynamic content changes they can change application behaviour without modifying the code itself
- They store sensitive information (like API keys) keeping them invisible in repositories
- The same variable name can be allocated across environments, but contain different information like paths
- Useful to help anage different settings for development, testing, and production
- They help with cross-platform code compatibility when storing OS specific data

---
class: contentpage
### **2.1 Setting environmental variables in Windows**

Create a temporary environmental variable for current session only - make the variable name unique!  
In Command Prompt then Powershell:  
```sh
set MY_VARIABLE=my_value
$env:MY_VARIABLE = "my_value"
```
Permanent for the logged in user.  
Using Command Prompt then Powershell:  
```sh
setx MY_VARIABLE "my_value"
[System.Environment]::SetEnvironmentVariable("MY_VARIABLE", "my_value", "User")
```
System-wide using PowerShell run as Administrator:
```sh
[System.Environment]::SetEnvironmentVariable("MY_VARIABLE", "my_value", "Machine")
```
---
class: contentpage
### **2.1 Setting environmental variables in Unix**

You can create temporary, permanent and system wide environmental variables.
Temporary variable to be used only in your current session:
```sh
export MY_VARIABLE="my_value"
```
Permanent for a specific user creating the variable. Depending on the shell being used you would add this to `~/.bashrc`, `~/.bash_profile`, or `~/.zshrc`:
```sh
echo 'export MY_VARIABLE="my_value"' >> ~/.bashrc
source ~/.bashrc
```
You can add a system-wide environment variable so all users/automations to easily access add them:
```sh
sudo echo 'MY_VARIABLE="my_value"' >> /etc/environment
sudo nano /etc/environment
```
To make the variable available you need to run this command then log in the server again plus log out and in again:
```sh
source /etc/environment
```
---

class: contentpage
### **2.2 Accessing environmental variables in code**

You have seen may examples of this already, particulary in the example bash scripts
```sh
"$ENV_VARIALBLE"
echo $ENV_VARIABLE
```
<font color="orange">Practise:</font> In a Python REPL try using the `os` module to create, get and delete variables.
```python3
import os

# Set an environmental variable in the current process only
os.environ['NEW_VARIABLE'] = 'my new data'

# Retrieve environmental variable
variable = os.environ.get('VARIABLE_NAME')

# Safely check if the environmental variable exists
if 'VARIABLE_NAME' in os.environ:
    return True
else:
    return False

# To delete an environmental variable in current process only
if 'NEW_VARIABLE' in os.environ:
    del os.environ['NEW_VARIABLE']
```
---
class: contentpage
### **2.2 Accessing environmental variables in code**

Python's `python-dotenv` module can store sensitive information across development versions. This data is stored in a '.env' file which can be excluded from version control. They can also be useful if you need to keep environmental variable separate between different stagings on one server, when running development, testing and production environments.

The project can be installed from PyPi.
```sh
pip install python-env
```

To configure the development environment, add a .env in the root directory of your project:
```
.
├── .env
└── script.py
```

```python3
from dotenv import load_dotenv
import os
load_dotenv()

# Access the variables
secret_key = os.getenv('SECRET_KEY')
```
---
class: contentpage
### **3. Expanding workflows with APIs**


.center[<img src="https://raw.githubusercontent.com/digitensions/summer-school-2024-local/main/thursday/images/Screenshot 2024-09-22 at 12.39.31.png" width="840">]


---
class: contentpage
### **3.1 RESTful API basics**

RESTful API (REpresentational State Transfer) allow two systems to exchange information over the internet, using HTTP methods GET, PUT, POST, DELETE.

Key elements of RESTful APIs include:
- Client or software on user computer initiates the communication
- Server offers the API as a means of accessing its data or service
- The client retrieves a resource from the API

Each REST message sent and received is self-descriptive which means they contain the requested data, but also information about how to interpret and process them.

Different HTTP response codes are returned depending on the success of you call:
- 200 reports that a request has been successful
- 201 can sometimes be used to report a successful create (POST) 
- 400 Bad Request is returned when something is wrong with the call or the endpoint
- 404 Not Found is returned when an API URL is incorrect or the API is off-line
- 401 is returned when an unauthorised request is placed

---
class: contentpage
### **3.1 RESTful API basics**

- An endpoint URL for the API
```sh
URL = "http://127.0.0.1:5000/api/v1/resources/books"
```
- The HTTP method for Create (POST), Read (GET), Update (PUT), Delete (DELETE) - A 'CRUD' action
```sh
POST
```
- HTTP headers such as authentication tokens or content type confirmation
```sh
"content-type": "application/json"
"accept": "application/json"
"apikey": os.environ['API_KEY']
```
- Body data usually supplied in XML or JSON encoded strings
```sh
{
  "title": "Titus Groan",
  "author": "Mervyn Peake",
  "first_sentence": "Gormenghast, that is, the main massing of the original stone, taken by itself would have displayed a certain ponderous architectural quality were it possible to have ignored the circumfusion of those mean dwellings that swarmed like an epidemic around its outer walls",
  "year_published": "1968"
}
```
---
class: contentpage
### **3.2 Requests library**

Requests is the standard method for sending HTTP requests in Python. The library simplifies the process of sending and receiving, leaving developers with more time to process the data received!

Let try using the requests library using a Flask API linked to a database of sci-fi book authors. Flask is a micro web framework written in Python that is well-suited for building REST APIs due to its flexibility and simplicity. This API has no authentication requirements and requires the wifi to be on.

<font color="orange">Practise:</font> Load your Python REPL from your VENV, and check if requests is installed. If not call `pip install requests`. Then test a simple GET request and look at the different responses available:
```python
import requests

# Set the URL for retrieving all contents
URL = "http://127.0.0.1:5000/api/v1/resources/books/all"

# Create the HTTP GET request
response = requests.get(url)

# Assess the reponse data
print(f"Method used: {response.request.method}")
print(f"Response status code: {response.status_code}"")
print(f"Content-Type: {response.headers.get('Content-Type')})
print(f"Response date: {response.headers.get('Date')})
print(f"Response: {response.json()}")
```

---
class: contentpage
### **3.2 Requests library**


If you load this web page in your browser we can view the book samples pre-loaded into the SQLite database the Flask API is connected to:
```sh
127.0.0.1:5000/api/v1/resources/books/all
```
<font color="orange">Practise:</font> Try more focused GET requests by picking an author and searching for the author's name, publishing date or title of the book:
```python3
import requests

URL = "http://127.0.0.1:5000/api/v1/resources/books"

query = {
  "author": "China Mieville"
}

book = requests.get(URL, params=query, verify=False)
print(book.text)
print(book.json())
```

---
class: contentpage
### **3.2 Requests library**

<font color="orange">Practise:</font> Let's make a POST request using a book sample from the repository path `thursday_scripts/api/new_books.json`. The payload dictionary need wrapping in `json.dumps()` method, and ensure you include the headers needed to inform the API how the POST data is formatted:

```python
import json
import requests

URL = "http://127.0.0.1:5000/api/v1/resources/books"
HEADERS = {'Content-Type': 'application/json'}

# Populate a JSON dictionary with sample data from the new_books.json and pick a unique ID 
# to avoid replicating another user's POST

payload =  {
  "id": 49,
  "title": "Titus Groan",
  "author": "Mervyn Peake",
  "first_sentence": "Gormenghast, that is, the main massing of the original stone...",
  "year_published": "1968"
}

response = requests.post(URL, headers=HEADERS, data=json.dumps(payload))
print(response.json())
```
---
class: contentpage
### **3.2 Requests library**

Call all the books again to see if your new book is there:
```python
URL = "http://127.0.0.1:5000/api/v1/resources/books/all"
response = requests.get(URL)
print(respons.json())
```
<font color="orange">Practise:</font> Finally, let's delete our book again using the DELETE request. Import JSON again to format the delete query. Select the title and unique ID of your book just written and build a query dictionary to identify the record for deletion.
```python
import json
import requests

URL = "http://127.0.0.1:5000/api/v1/resources/books"
HEADERS = {'Content-Type': 'application/json'}

query = {
  "title": "Titus Groan",
  "id": 49
}

response = requests.delete(URL, headers=HEADERS, data=json.dumps(query))
print(response.json())
```
---
class: contentpage
### **3.3 Rate limiting**
 
API rate limiting is a technique used to control the number of requests that a client can make to an API within a specified period.
- Rate limiting protects against Denial-of-Service (DoS) attacks and offenses like spamming API endpoints
- By limiting requests, servers can efficiently manage resources so no one client can dominate access
- It can save money when APIs are based in cloud environments and charged based on usage
- There may be legal or contractual obligations to limit data throughput or access

If you encounter problems you can manage the way your code calls the API by using Python tools like `ratelimit` to control how often your requests are made to an API:

```python3
from ratelimit import limits
import requests

FIFTEEN_MINUTES = 900

@limits(calls=15, period=FIFTEEN_MINUTES)
def call_api(url):
    response = requests.get(url)

    if response.status_code != 200:
        raise Exception('API response: {}'.format(response.status_code))
    return response
```
---
class: contentpage
### **3.4 AWS S3 cloud storage**  

Not all RESTful APIs use Python `requests` library for access. Amazon Web Service Simple Storage Service (AWS S3) has an Software Developer Kit (SDK) which uses a Python package called boto3. S3 is an object storage service from AWS, very popular for video and image storage and reliable. Being able to connect your scripts to it can help create scalable applications.

`Boto3` allows you to directly create, update and delete AWS resources from Python.
```sh
pip install boto3
```
To work with the AWS SDK you need to complete a few steps:
- Create an AWS user account 
- Select your access type as 'Programmatic access' to receive your access key ID and secret key
- Select an access policy and create a user account name

Next return to your command line and configure the AWS credentials, then open the credentials and add:
```sh
toucn ~/.aws/credentials

[default]
aws_access_key_id = YOUR_ACCESS_KEY_ID
aws_secret_access_key = YOUR_SECRET_ACCESS KEY
```
---
class: contentpage
### **3.4 AWS S3 cloud storage**  

Connect as a client to your AWS S3 SDK:
```python3
import boto3
s3_client = boto3.client('s3')
```
You can create a bucket. You need to create a unique name across all AWS buckets globally, so it may help to generate a Unique ID, with `uuid` package. Buckets can be 3 to 63 characters long:
```python3
import uuid
bucket_name = f"BFI_{str(uuid.uuid4())}"

s3_resource.create_bucket(Bucket=bucket_name, 
                          CreateBucketConfiguration={
                              'LocationConstraint': 'eu-west-2'})
```
You also need to add the bucket configuration with your location.
---
4. Elasticsearch and MySQL connections  
 4.1 Elasticsearch Indexing, searching documents     
 4.2 Connecting to MySQL databases  
 4.3 Search and retrieval with sqlite3 



    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js" type="text/javascript"></script>
    <script type="text/javascript">var slideshow = remark.create({ratio: "16:9"});</script>
  </body>
</html>